import argparse
import json
from typing import Any, Dict

from google.cloud import aiplatform
from kfp.v2 import compiler

_default_pipeline_params: Dict = {}


class VertexPipeline:

    display_name = "default"

    def pipeline(self, *args: Any, **kwargs: Any) -> None:
        pass

    def compile_pipeline(self, package_path: str) -> None:
        """Compile the pipeline"""
        compiler.Compiler().compile(
            pipeline_func=self.pipeline,
            package_path=package_path,
        )

    def run_job(
        self,
        template_path: str,
        pipeline_root: str,
        project: str,
        region: str,
        pipeline_params: Dict[str, Any] = _default_pipeline_params,
    ) -> None:
        """Run the pipeline"""
        job = aiplatform.PipelineJob(
            display_name=self.display_name,
            template_path=template_path,
            pipeline_root=pipeline_root,
            parameter_values=pipeline_params,
            project=project,
            location=region,
            enable_caching=False,
        )
        job.run()

    def parse_args(self) -> argparse.Namespace:
        """Parse arguments"""
        parser = argparse.ArgumentParser(description="Compile or run a Vertex Pipeline")

        commands = parser.add_subparsers(help="commands", dest="command", required=True)

        # compile command arguments
        cmd_compile = commands.add_parser(
            "compile", help="compile pipeline function to a json package file."
        )
        cmd_compile.add_argument(
            "--template_path",
            required=True,
            help="path to compiled pipeline package file.",
        )

        # run command arguments
        cmd_run_job = commands.add_parser(
            "run", help="run pipeline job on AI platform."
        )
        cmd_run_job.add_argument("--project", required=True, help="project ID.")
        cmd_run_job.add_argument("--region", required=True, help="region.")
        cmd_run_job.add_argument(
            "--template_path",
            required=True,
            help="path to compiled pipeline package file.",
        )
        cmd_run_job.add_argument(
            "--pipeline_params",
            required=True,
            help="Pipeline params file.",
        )
        cmd_run_job.add_argument(
            "--pipeline_root",
            required=True,
            help="GCS root directory for files generated by pipeline job.",
        )

        return parser.parse_args()

    def main(self, args: argparse.Namespace) -> None:
        if args.command == "compile":
            self.compile_pipeline(args.template_path)
        elif args.command == "run":
            aiplatform.init()

            with open(args.pipeline_params) as json_file:
                pipeline_params = json.load(json_file)

            print(pipeline_params)

            self.run_job(
                template_path=args.template_path,
                pipeline_root=args.pipeline_root,
                project=args.project,
                region=args.region,
                pipeline_params=pipeline_params,
            )
        else:
            print(f"Command not implemented: {args.command}")
